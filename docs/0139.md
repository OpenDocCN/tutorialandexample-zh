# 动态贝叶斯网络

> 原文：<https://www.tutorialandexample.com/dynamic-bayesian-networks/>

DBN 是一种临时网络模型，用于将相邻时间步长的变量相互关联起来。动态贝叶斯网络的每个部分可以有任意数量的用于状态表示的**X<sub>I</sub>T3】变量，以及证据变量 **E <sub>t</sub>** 。DBN 是一种贝叶斯网络。动态贝叶斯网络是由保罗·达格门在 20 世纪 90 年代早期在斯坦福大学开发的。**

### DBN 和嗯有什么不同？

隐马尔可夫模型(HMM)可以表示为具有单个状态变量和证据变量的动态贝叶斯网络。另一方面，DBN 可以转换成 HMM。两者的区别在于，通过将复杂的系统状态分解成其组成变量，DBN 利用了时间概率模型中的稀疏性。因此，HMM 和 DBN 之间的关系是相似的。

### 隐马尔可夫模型的缺点

*   嗯需要更多的空间
*   转移矩阵是巨大的，这导致了昂贵的马尔可夫模型。
*   HMM 不用于解决大问题，因为不可能学习这么多参数。

**建筑 DBN**

**在构建动态贝叶斯网络时，需要指定以下三种信息:**

1.  状态变量的先验分布 **P(X <sub>0</sub> )**
2.  过渡模型**P(X<sub>t+1</sub>| X<sub>t</sub>)**
3.  传感器型号 **P(E <sub>t</sub> |X <sub>t</sub> )**

为了指定转换和传感器模型，连接的拓扑出现在连续切片之间，以及证据和状态变量之间。这是因为假设这两个模型是静态的。

**DBN 的推论**

在动态贝叶斯网络中讨论了两种类型的推理:

*   DBN 的精确推理
*   DBN 的近似推理

**DBN 的确切推断**

通过复制切片来完成观察，可以构建 DBN 的完整贝叶斯网络。这种技术被称为**展开**。一个简单的应用程序是没有效率的，因为推理时间会随着新的观察而增加。相反，我们可以通过只记住两个切片来使用增量方法。

**DBN 的近似推论**

有了精确推理方法，也有可能使用近似推理方法。近似方法，如**似然加权，马尔可夫链蒙特卡罗**，是容易适应 DBN 环境的方法。似然法的工作原理是以拓扑方式对非暴力节点进行采样。直接在展开的 DBN 上应用似然方法是容易的，但是会导致高时间和更多空间需求的问题。这是因为标准算法通过网络一路运行每个样本。另一种方法是通过 DBN 一起运行所有的 **N** 个样本，一次执行一个切片。因此，我们使用不同的创新技术来提供最佳方法:

首先，使用样本本身作为当前状态分布的近似表示。

其次，关注状态空间的高概率区域上的样本集。

因此，为了做到这一点，我们使用了一系列被称为**粒子滤波**的算法。**算法的工作原理是:**

1.  通过从先前分布 P(X <sub>0</sub> )中采样来创建初始状态 **N** 样本的群体。
2.  更新周期每次重复如下:
3.  通过对下一个状态值**X<sub>t+1</sub>T3】进行采样，在正向上传播每个样本，其中当前状态 X <sub>t</sub> 是基于转换模型给出的。**
4.  样本按分配给新证据的可能性进行加权。
5.  对总体进行重新采样，以生成 N 个样本的新总体。

**我们来看看粒子滤波算法:**

**函数**粒子滤波器(e，N，dbn)为下一时间步返回一组样本

**输入:** e，新输入的证据

n，需要保持的样本数量

dbn，具有先验 P(X0)、转移模型 P(X1|X0)、传感器模型 P(E1|X1)的动态贝叶斯网络

**持久:** S，大小为 N 的样本向量，最初从 P(X0)生成

**局部变量:** W，大小为 N 的权重向量

对于 i = 1 到 N do

S[i ]？来自 P(X1 | X0 = S[i ])的样本/*步骤 1 */

W[i ]？P(e | X1 = S[i]) /*第二步*/

s？替换加权样本(N，S，W) /*步骤 3 */

返回 S

因此，粒子滤波是一致且有效的技术，因为该算法通过使用恒定数量的样本来保持对真实后验的良好近似。